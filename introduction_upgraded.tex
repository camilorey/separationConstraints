\section{Introduction}\label{sec:introduction}
The success of Deep Learning has been linked to its ability to learn \emph{abstract representations} from input data in a hierarchical fashion  \cite{LeCun06atutorial,ramachandranEtAl2017SearchingForActivationFunctions}. However, depth is also instrumental in various DNN \emph{issues} like the \emph{vanishing gradient} as presented in \cite{vanishing1} or \cite{vanishing2}; the \emph{exploding gradient} as presented in \cite{exploding}; the \emph{dead unit problem} as presented in \cite{leaky},\cite{whyreludie} or \cite{whenneuronsfail}; or the \emph{degradation problem} as presented in \cite{resnet}. 
\\\\
Existing methods attempt to fix these issues by regulating abstract representation formation in deference to the back-propagation of error (as a learning strategy) comprising two families of approaches, summarized for the reader in Table \ref{tab:techniquesTable}: (1) \emph{architectural modifications} and (2) \emph{data manipulations}. 
\\\\
By architectural modifications we mean methods that profit from the feed-forward structure of DNN to secure meaningful back-propagation. Particularly, we wish to draw attention to the \emph{layer width increase} strategy. As DNN become deeper, a common belief is to increase the width of deeper layers to reduce the probability of dead units, dead points and degradation. However, as described for example in the \emph{SimpNet} \cite{simpnet}, there is an optimal layer width, over which accuracy begins to diminish.  
\\\\
In the case of \ReLU based DNN, we claim that these issues occur amidst several geometric undertows, that when unamanged, corrupt back-propagation. More specifically, we contend that gradient issues (vanishing and exploding) alongside with death problems (unit and point) are intertwined with the position of the hyper-planes defined by the preactivation of \ReLU units \emph{relative} to the dataset. During the training process, these hyperplanes move and rotate depending on the gradient of the loss functional.    
\\\\
As shown by Rey-Torres et al. \cite{reyRiera2019ModellingClassificationReLU}), loss gradient (with regards to parameters) is a linear transformation of dataset points (or their abstract representation), that features a product with with a diagonal matrix comprised of characteristic functions of the positive hemi-spaces defined by units (see section 2 of \cite{reyRiera2019ModellingClassificationReLU}). As we present in Section \ref{sec:separability} on Separability, dead units, dead points and the vanishing gradient are all present in the negative hemi-spaces of layers \cite{reyRiera2019ModellingClassificationReLU}. 
\\\\
In this sense, the fundamental issue underlying both dead units, dead points, degradation, and the vanishing gradient is actually \emph{improper plane positioning} with regards to the data-set, in the sense of the notion of \emph{separability} as present in detail in section \ref{sec:separability}. 
\\\\
We can correct plane positioning enforcing a set of \emph{separation constraints} (the heart of our proposal) as detailed in section \ref{sec:constraint}). These  can be made to target specifically the dead unit problem (defining the unit-based separation constraint \SepUnit); and the dead point problem (using a point-based separation constraint \SepPoint). Intuitively, the separation constraints secure \emph{proper separations} by securing that the hyperplanes \emph{cut} throughout the dataset (following Section \ref{sec:separability}). The constraint formulation neither tampers with the feed-forward structure of DNN, nor uses any \emph{post-hoc} geometric transformations on data: it becomes an alternate method to attack aforementioned issues. 
\\\\
However, the dynamics of \ReLU DNN is much richer, as we describe in our Experiments (Section \ref{sec:experiments}) when testing the separation constraints over the \texttt{MOONS} and \text{MNIST} datasets. Degradation begins to play an important part on \ReLU-based separation problems, and dead units begin to give way to \emph{repeated units}. In a nutshell: in deeper networks, these issues become instrumental in the development of accuracy. Our insights on the mechanics and dynamics \ReLU-based DNN separation, are detailed throughout our Final Remarks (Section \ref{sec:conclusions}).  

\begin{table*}[h!]
\centering
\begin{tabular}{@{}llll@{}}
\toprule
Family & Method & Examples & Intended issues\\ 
\midrule
%\multirow{3}{*}
Architectural & Width increase & \begin{tabular}[c]{@{}l@{}}
 Wide \texttt{ResNet} \cite{wideresnet}\\ 
\texttt{Inception} \cite{inceptionv1}\\
\end{tabular}                                                                 
& \begin{tabular}[c]{@{}l@{}}
Vanishing Gradient\\ 
Increase Depth
\end{tabular}    \\
& 
\begin{tabular}[c]{@{}l@{}}
Connection \\ 
modification
\end{tabular} 
& \begin{tabular}[c]{@{}l@{}}
 \texttt{ResNet} \cite{resnet} \\
 \texttt{DenseNet}\cite{densenet}\\
\end{tabular}                                   
& \begin{tabular}[c]{@{}l@{}}
Vanishing Gradient\\ 
\\ 
Increase Depth\end{tabular} 
\\
& Unit Alteration                                                    
& \begin{tabular}[c]{@{}l@{}}
\emph{leaky}-\ReLU \cite{leaky} \\ 
\texttt{PReLU} \cite{prelu}\\ 
\texttt{C-ReLU} \cite{crelu}
\end{tabular} & \begin{tabular}[c]{@{}l@{}}
Vanishing Gradient\\ 
Dead Neurons
\end{tabular} \\
Data Manipulation & Modify layer output & \emph{batch normalization} \cite{batchnorm}  & Exploding Gradient                  \\ 
\bottomrule
\end{tabular}
\caption{Summary of techniques commonly used in deep learning to overcome issues like enhanced depth, vanishing/exploding gradient and dead neurons.}
\label{tab:techniquesTable}
\end{table*}

